{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klousss/applied_ai/blob/main/ai_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Практическая работа №3. Свёрточные нейронные сети"
      ],
      "metadata": {
        "id": "IoK0UrGtAOlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Работу выполнил (а):**\n",
        "\n",
        "ФИО, ИТМО ID"
      ],
      "metadata": {
        "id": "5kkoxPG8AXsj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHy7vziiPnC"
      },
      "source": [
        "# Классификация цветов с помощью свёрточных нейронных сетей.\n",
        "\n",
        "\n",
        "В работе необходимо познакомится с различными архитектурами сверхточных нейронных сетей и их обучением на GPU (англ. graphics processing, графический процессор) на языке программирования Python 3 и фреймворка Torch (PyTorch).  Для этого предлагается использовать ресурсы Google Colab - Colaboratory, для выполнения вычислений на GPU. После с ознакомления, выполнить практическое задане в конце данной тетради (notebook).\n",
        "\n",
        "Рассмотрим [Датасет](https://www.kaggle.com/alxmamaev/flowers-recognition ) содержащий 4242 изображения цветов размеченных по 5 видам (тюльпан, ромашка, подсолнух, роза, одуванчик). Данный набор данных можно скачать по [ссылке](https://www.kaggle.com/alxmamaev/flowers-recognition ) с сайте kaggle.\n",
        "\n",
        "Загрузите папку с картинками на гугл диск, чтобы не загружать ее каждый раз заново при перезапуске колаба. Структура файлов (можно посмотреть в меню слева) может быть такой: \"/content/drive/My Drive/data/flowers\".\n",
        "\n",
        "Обязательно подключите аппаратный ускоритель (GPU) к среде выполнения. В меню сверху: Среда выполнения -> Сменить среду выполнения\n",
        "\n",
        "Первым делом разберите более детально код выполнив код ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRteSKZ5VKai"
      },
      "source": [
        "# Подготовка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXtAgtr2V3u6"
      },
      "source": [
        "Загружаем библиотеки. Фиксируем random.seed для воспроизводимости"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvM84NDjxCnK"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjYDp6nXWWmQ"
      },
      "source": [
        "Выбираем на чем будем делать вычисления - CPU или GPU (cuda)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzyQGtNfzMsI",
        "cellView": "code"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Блок для соединения с Google Colab"
      ],
      "metadata": {
        "id": "6AUK8d5HKdYB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrcMAZywKnKK"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "FOLDERNAME = 'data/flowers'\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "#%cp -r $FOLDERNAME ../../\n",
        "#%cd ../../\n",
        "%cd data/flowers/\n",
        "#!bash get_datasets.sh\n",
        "#%cd ../../\n",
        "\n",
        "#+For kaggle______________________________________________\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "# FOLDERNAME = '/kaggle/input/flowers-recognition/flowers'\n",
        "# %cd /kaggle/input/flowers-recognition/flowers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV-txOlLyJhK"
      },
      "source": [
        "prepare_imgs = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize((224, 224)), #приводим картинки к одному размеру\n",
        "        torchvision.transforms.ToTensor(), # упаковывем их в тензор\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] # нормализуем картинки по каналам\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "# задаем датасет. Лейблы - имена папок:\n",
        "dataset = ImageFolder('/content/drive/My Drive/data/flowers', transform=prepare_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcuefCcB8iwi"
      },
      "source": [
        "dataset.imgs[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_DuonGn5HVb"
      },
      "source": [
        "class ValueMeter(object):\n",
        "  \"\"\"\n",
        "  Вспомогательный класс, чтобы отслеживать loss и метрику\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      self.sum = 0\n",
        "      self.total = 0\n",
        "\n",
        "  def add(self, value, n):\n",
        "      self.sum += value*n\n",
        "      self.total += n\n",
        "\n",
        "  def value(self):\n",
        "      return self.sum/self.total\n",
        "\n",
        "def log(mode, epoch, loss_meter, accuracy_meter, best_perf=None):\n",
        "  \"\"\"\n",
        "  Вспомогательная функция, чтобы\n",
        "  \"\"\"\n",
        "  print(\n",
        "      f\"[{mode}] Epoch: {epoch:0.2f}. \"\n",
        "      f\"Loss: {loss_meter.value():.2f}. \"\n",
        "      f\"Accuracy: {100*accuracy_meter.value():.2f}% \", end=\"\\n\")\n",
        "\n",
        "  if best_perf:\n",
        "      print(f\"[best: {best_perf:0.2f}]%\", end=\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rhIMxkeVTGj"
      },
      "source": [
        "# Сверточная нейросеть с нуля\n",
        "\n",
        "## Вручную прописываем слои"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeRibccoyT_A"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256*28*28, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 5))\n",
        "model.to(device) # отправляем модель на девайс (GPU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAA16XH3YbLI"
      },
      "source": [
        "Задаем гиперпараметры для обучения:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP0M3cL8ZDd3"
      },
      "source": [
        "# Задаем параметры и функцию для обучения. Разбиваем датасет на train/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwhX2vdquink"
      },
      "source": [
        "batch_size = 32\n",
        "optimizer = torch.optim.Adam(params = model.parameters())\n",
        "lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG0zjMWDYu32"
      },
      "source": [
        "Разбиваем датасет на train и validation\n",
        "\n",
        "Задаем dataloader'ы - объекты для итеративной загрузки данных и лейблов для обучения и валидации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2AW1YTupITs"
      },
      "source": [
        "train_set, val_set = torch.utils.data.random_split(dataset, [len(dataset)-1000, 1000])\n",
        "print('Размер обучающего и валидационного датасета: ', len(train_set), len(val_set))\n",
        "loaders = {'training': DataLoader(train_set, batch_size, pin_memory=True,num_workers=2, shuffle=True),\n",
        "           'validation':DataLoader(val_set, batch_size, pin_memory=True,num_workers=2, shuffle=False)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuiJKWrYZZgb"
      },
      "source": [
        "Функция для подсчета Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm15u4TsDcIY"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzW60Io-riGV"
      },
      "source": [
        "Функция для обучения и валидации модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdlXyjEGhU4W"
      },
      "source": [
        "def trainval(model, loaders, optimizer, epochs=10):\n",
        "    \"\"\"\n",
        "    model: модель, которую собираемся обучать\n",
        "    loaders: dict с dataloader'ами для обучения и валидации\n",
        "    \"\"\"\n",
        "    loss_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "    accuracy_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "\n",
        "    loss_track = {'training': [], 'validation': []}\n",
        "    accuracy_track = {'training': [], 'validation': []}\n",
        "\n",
        "    for epoch in range(epochs): # итерации по эпохам\n",
        "        for mode in ['training', 'validation']: # обучение - валидация\n",
        "            # считаем градиаент только при обучении:\n",
        "            with torch.set_grad_enabled(mode == 'training'):\n",
        "                # в зависимоти от фазы переводим модель в нужный ружим:\n",
        "                model.train() if mode == 'training' else model.eval()\n",
        "                for imgs, labels in tqdm(loaders[mode]):\n",
        "                    imgs = imgs.to(device) # отправляем тензор на GPU\n",
        "                    labels = labels.to(device)\n",
        "                    bs = labels.shape[0]  # размер батча (отличается для последнего батча в лоадере)\n",
        "\n",
        "                    preds = model(imgs) # forward pass - прогоняем тензор с картинками через модель\n",
        "                    loss = F.cross_entropy(preds, labels) # считаем функцию потерь\n",
        "                    acc = accuracy(preds, labels) # считаем метрику\n",
        "\n",
        "                    # храним loss и accuracy для батча\n",
        "                    loss_meter[mode].add(loss.item(), bs)\n",
        "                    accuracy_meter[mode].add(acc, bs)\n",
        "\n",
        "                    # если мы в фазе обучения\n",
        "                    if mode == 'training':\n",
        "                        optimizer.zero_grad() # обнуляем прошлый градиент\n",
        "                        loss.backward() # делаем backward pass (считаем градиент)\n",
        "                        optimizer.step() # обновляем веса\n",
        "            # в конце фазы выводим значения loss и accuracy\n",
        "            log(mode, epoch, loss_meter[mode], accuracy_meter[mode])\n",
        "\n",
        "            # сохраняем результаты по всем эпохам\n",
        "            loss_track[mode].append(loss_meter[mode].value())\n",
        "            accuracy_track[mode].append(accuracy_meter[mode].value())\n",
        "    return loss_track, accuracy_track"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMhG1AtAau9k"
      },
      "source": [
        "# Обучаем базовую модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnDPDjYuxMAi"
      },
      "source": [
        "Проверим загрузку видеокарты, прежде чем запустить обучение:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAT9SPrzxZH7"
      },
      "source": [
        "Запускаем обучение на 10 эпох"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czmf2yVKvEYY"
      },
      "source": [
        "loss_track, accuracy_track = trainval(model, loaders, optimizer, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAmfxowdRLfQ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(accuracy_track['training'], label='training')\n",
        "plt.plot(accuracy_track['validation'], label='validation')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.grid()\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def predict_image(img, model):\n",
        "    # Преобразование to a batch of 1\n",
        "    xb = img.unsqueeze(0).to(device)\n",
        "    # Получение прогнозов от модели\n",
        "    yb = model(xb)\n",
        "    # Выбираем индекс с наибольшей вероятностью\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Получение метки класса\n",
        "    return dataset.classes[preds[0].item()]\n",
        "\n",
        "for i in range(1,10):\n",
        "  img, label = val_set[i]\n",
        "  plt.imshow(img.clip(0,1).permute(1, 2, 0))\n",
        "  plt.axis('off')\n",
        "  plt.title('Label: {}, Predicted: {}'.format(dataset.classes[label],predict_image(img, model)))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "YR0_O_fXQ2s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rtKZrQF0oma"
      },
      "source": [
        "# Практическое задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27qiLUtR011m"
      },
      "source": [
        "\n",
        "\n",
        "В задние представлено логика выполнения с использование tensorflow/keras. Выполнять можно как с использованием tensorflow/keras, так и pytorch.\n",
        "\n",
        "1. Необходимо обучить предобученную сверточную архитектуру для задач классификации цветов.\n",
        "\n",
        "В выбранной Вами архитектуре также необходимо **разобраться** с основными её параметрами и принципами работы.\n",
        "\n",
        "Посмотрите как использовать [модели в PyTorch](https://pytorch.org/vision/stable/models.html) для классификации, выберите одну и используя transfer learning до-обучите модель на классификацию цветов. Чтобы это сделать замените ____ в ячейках ниже на работающий код.\n",
        "\n",
        "2. Реализовать свою архитектуру, также как в разделе \"Сверточная нейросеть с нуля\".\n",
        "\n",
        "3. Сравнить три архитектуры (из раздела \"Сверточная нейросеть с нуля\", предобученую сверточную архитектуру и свою архитектуру (из п. 2)). Визуализировать полученный результат сравнения.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Обучение предобученной сверточной архитектуры для задач классификации цветов"
      ],
      "metadata": {
        "id": "i3L29dCHCS6l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZGKQ77DqT31"
      },
      "source": [
        "\n",
        "# Выберите модель из списка доступных в PyTorch моделей\n",
        "# Не забудьте указать, что она модель должна быть предобучена!\n",
        "# Написать свой код здесь....\n",
        "model = torchvision.models.()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVgqf7x4aOo"
      },
      "source": [
        "# Функция для заморозки весов модели\n",
        "def set_parameter_requires_grad(model):\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "set_parameter_requires_grad(_____) # передайте модель в функцию для \"заморозки\" градиента"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXqwU5Rd5DYs"
      },
      "source": [
        "model._____ = _____# Меняем последний слой модели Зачем? Сколькой нужно выходов?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaquxdRWJ_LK"
      },
      "source": [
        "# Проверим все ли сработало правильно, выведем веса, которые будут обучаться\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTE0EUG9lh5g"
      },
      "source": [
        "model.to(_____) # Отправляем модель на GPU\n",
        "optimizer = () # алгоритм оптимизации\n",
        "loss_track, accuracy_track = trainval(____, loaders, optimizer, epochs=_____) #обратить внимание на loss_track и accuracy_track"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3npGmGBsoZfe"
      },
      "source": [
        "plt.plot(accuracy_track['training'], label='training')\n",
        "plt.plot(accuracy_track['validation'], label='validation')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.grid()\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atswap6Qojha"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0).to(device)\n",
        "    yb = model(xb)\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    return dataset.classes[preds[0].item()]\n",
        "\n",
        "for i in range(1,10):\n",
        "  img, label = val_set[i]\n",
        "  plt.imshow(img.clip(0,1).permute(1, 2, 0))\n",
        "  plt.axis('off')\n",
        "  plt.title('Label: {}, Predicted: {}'.format(dataset.classes[label],predict_image(img, _____)))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0zHu9uIo1Df"
      },
      "source": [
        "По желанию, можно сохранить веса модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC6KLbr5pBjd"
      },
      "source": [
        "weights_fname = '/content/drive/My Drive/data/***___**.pth'\n",
        "torch.save(____.state_dict(), weights_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Своя архитектура"
      ],
      "metadata": {
        "id": "bAZ_cU_ZAwFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Написать свой код здесь\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bdWjA7z1C1CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Сравнение и вузуализация 3-х архитектур"
      ],
      "metadata": {
        "id": "0iOkiynqDFCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Написать свой код здесь\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5_mSZEZxDNak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEwPBvRvkASl"
      },
      "source": [
        "## Вопросы.\n",
        "Добавте описание архитектуры выбранной Вами предобученой сверточной нейронной сети.\n",
        "\n",
        "Как работает выбранная вами модель сверточной нейронной сети? Какие параметры?\n",
        "\n",
        "В чем основные отличия между сверточной нейронной сетью и \"обычной\" полносвязной нейронной сетью?\n",
        "\n",
        "Что такое transfer learning? Что такое предобучена нейронная сеть?\n",
        "\n",
        "Что такое функция для заморозки весов модели?\n",
        "\n",
        "Как работает блок \"Сверточная нейросеть с нуля\"? Описать сверточный и пулинговый слой."
      ]
    }
  ]
}